{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################start##############################\n",
    "import pandas as pd\n",
    "df=pd.read_csv('./datas/Data_MergeNew.csv',index_col=0)\n",
    "df.index=pd.to_datetime(df.date,format='%Y-%m-%d') \n",
    "df.drop('date',axis=1,inplace=True)\n",
    "df_train=df.loc['2020-01-07':'2021-04-02'] \n",
    "df_test=df.loc['2021-04-02':'2021-04-23']\n",
    "\n",
    "name=['cityin','cityto','incity','city']\n",
    "name1=['cityin','cityto','incity']\n",
    "x_train=df_train.drop(name,axis=1).values  \n",
    "y_train=df_train[name1].values\n",
    "x_test=df_test.drop(name,axis=1).values  \n",
    "y_test=df_test[name1].values\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "#####################标准化##############################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(x_train)\n",
    "x_train = ss.transform(x_train) \n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 中文字体设置-黑体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n",
    "sns.set(font='SimHei',font_scale=1.5)  # 解决Seaborn中文显示问题并调整字体大小\n",
    "sns.set_style(\"white\")\n",
    "def mkdir(path):\n",
    "    folder = os.path.exists(path)\n",
    "    if not folder:                   \n",
    "        os.makedirs(path)            \n",
    "        print(\"---  new folder...  ---\")\n",
    "        print(\"---  OK  ---\")\n",
    "    else:\n",
    "        print(\"---  There is this folder!  ---\")\n",
    "mkdir(\"./results_merge/\")        \n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,median_absolute_error,r2_score,mean_squared_log_error\n",
    "\n",
    "def calculate(y_true, y_predict, n, p):\n",
    "    y_true = y_true\n",
    "    y_predict = y_predict\n",
    "    mse = mean_squared_error(y_true, y_predict)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_predict))\n",
    "    mae = mean_absolute_error(y_true, y_predict)\n",
    "    r2 = r2_score(y_true, y_predict)\n",
    "    mad = median_absolute_error(y_true, y_predict)\n",
    "    mape = np.mean(np.abs((y_true - y_predict) / y_true)) * 100\n",
    "    r2_adjusted = 1-((1-r2)*(n-1))/(n-p-1)\n",
    "    # print('MSE: ', mse)\n",
    "    # print('RMSE: ', rmse)\n",
    "    # print('MAE: ', mae)\n",
    "    # print('R2: ', r2)\n",
    "    # print('MAD:', mad)\n",
    "    # print('MAPE:', mape)\n",
    "    # print('R2_Adjusted: ',r2_adjusted)\n",
    "    return mse,rmse,mae,r2,mad,mape,r2_adjusted\n",
    "# 将参数和评估结果写入文件\n",
    "def write_csv_result(path_1,path_2,all_metrics,all_parameter):\n",
    "    with open(path_1,\"a\",encoding=\"utf-8\",newline=\"\")as f:\n",
    "        f = csv.writer(f)\n",
    "        f.writerow(all_metrics)\n",
    "    with open(path_2,\"a\",encoding=\"utf-8\",newline=\"\")as f:\n",
    "        f = csv.writer(f)\n",
    "        f.writerow(all_parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "def Svr(train_x,test_x,train_y,test_y,name):\n",
    "    path_a = \"./results_merge/\"  + \"Svr_\" + name + \"_\" + \"assess.csv\"\n",
    "    path_p = \"./results_merge/\"  + \"Svr_\" + name + \"_\" + \"parameter.csv\"\n",
    "    path_b = \"./results_merge/\"  + \"Svr_\" + name + \"_\" + \"best.csv\"\n",
    "    model_path = \"./results_merge/\"  + \"Svr_\" + name + \"_\" + \"best.m\"\n",
    "    # 人工设置网格搜索的范围\n",
    "    kernel = [\"rbf\",\"linear\",\"poly\",\"sigmoid\"]\n",
    "    degree = [2,3,4,5,6,7,8,9,10,11,12]\n",
    "    gamma = [\"auto\",\"scale\"]\n",
    "    all_nb = len(kernel) * len(degree) * len(gamma)\n",
    "    num=1\n",
    "    # 用于重启训练模型，提高效率，不重复跑相同的实验\n",
    "    if(os.path.exists(path_a)):\n",
    "        data = pd.read_csv(path_a)\n",
    "        if(data.shape[0]>1):\n",
    "            nums = int(data.values[-1,0])\n",
    "        else:\n",
    "            nums = 0\n",
    "    else:\n",
    "        nums = 0\n",
    "        col_a = ['num','mse','rmse','mae','r2','mad','mape','r2_adjusted','rmsle']\n",
    "        col_p = ['num','kernel','degree','gamma']\n",
    "        write_csv_result(path_a,path_p,col_a,col_p)\n",
    "    # 用于保存最好的模型\n",
    "    if(os.path.exists(path_b)):\n",
    "        best_result = 10*10**30\n",
    "    else:\n",
    "        with open(path_b,\"a\",encoding=\"utf-8\",newline=\"\")as f:\n",
    "            f = csv.writer(f)\n",
    "            f.writerow(['num','mse','rmse','mae','r2','mad','mape','r2_adjusted','rmsle'])\n",
    "        best_result = 10*10**30\n",
    "    # 网格搜索\n",
    "    for k in kernel:\n",
    "        for d in degree:\n",
    "            for g in gamma:\n",
    "                if(nums>=num):\n",
    "                    num = num+1\n",
    "                else:\n",
    "                    if(k==\"poly\"):\n",
    "                        print(\"SVR start....{}/{}\".format(num,all_nb))\n",
    "                        model = SVR(kernel=k,degree=d,gamma=g)\n",
    "                    elif(k==\"rbf\" or k==\"sigmoid\"):\n",
    "                        print(\"SVR start....{}/{}\".format(num,all_nb))\n",
    "                        model = SVR(kernel=k,gamma=g)\n",
    "                    else:\n",
    "                        print(\"SVR start....{}/{}\".format(num,all_nb))\n",
    "                        model = SVR(kernel=k)\n",
    "                    wrapper = RegressorChain(model)\n",
    "                    wrapper.fit(train_x,train_y)\n",
    "                    pred_test = wrapper.predict(test_x)\n",
    "#     \n",
    "                    y_test=test_y       \n",
    "                    y_test1=[]\n",
    "                    for i in y_test:\n",
    "                        y_test1.append(i[0])\n",
    "                    pred_test1=[]\n",
    "                    for i in pred_test:\n",
    "                        pred_test1.append(i[0])\n",
    "                    y_test2=[]\n",
    "                    for i in y_test:\n",
    "                        y_test2.append(i[1])\n",
    "                    pred_test2=[]\n",
    "                    for i in pred_test:\n",
    "                        pred_test2.append(i[1])\n",
    "                    y_test3=[]\n",
    "                    for i in y_test:\n",
    "                        y_test3.append(i[2])\n",
    "                    pred_test3=[]\n",
    "                    for i in pred_test:\n",
    "                        pred_test3.append(i[2])\n",
    "                    pred_test1 = np.array(pred_test1).reshape(-1,1)\n",
    "                    y_test1 = np.array(y_test1).reshape(-1,1)\n",
    "                    sample_n = pred_test1.shape[0]\n",
    "                    feature_n = x_test.shape[1]\n",
    "                    mse1,rmse1,mae1,r21,mad1,mape1,r2_adjusted1 = calculate(y_test1,pred_test1,sample_n,feature_n)\n",
    "                \n",
    "\n",
    "                    pred_test2 = np.array(pred_test2).reshape(-1,1)\n",
    "                    y_test2 = np.array(y_test2).reshape(-1,1)\n",
    "                    sample_n = pred_test2.shape[0]\n",
    "                    feature_n = x_test.shape[1]\n",
    "                    mse2,rmse2,mae2,r22,mad2,mape2,r2_adjusted2 = calculate(y_test2,pred_test2,sample_n,feature_n)\n",
    "                    \n",
    "\n",
    "                    pred_test3 = np.array(pred_test3).reshape(-1,1)\n",
    "                    y_test3 = np.array(y_test3).reshape(-1,1)\n",
    "                    sample_n = pred_test3.shape[0]\n",
    "                    feature_n = x_test.shape[1]\n",
    "                    mse3,rmse3,mae3,r23,mad3,mape3,r2_adjusted3 = calculate(y_test3,pred_test3,sample_n,feature_n)\n",
    "    \n",
    "                    mse,rmse,mae,r2,mad,mape,r2_adjusted = (mse1+mse2+mse3)/3,(rmse1+rmse2+rmse3)/3,(mae1+mae2+mae3)/3,(r21+r22+r23)/3,(mad1+mad2+mad3)/3,(mape1+mape2+mape3)/3,(r2_adjusted1+r2_adjusted2+r2_adjusted3)/3\n",
    "                    all_m = [num,mse,rmse,mae,r2,mad,mape,r2_adjusted]\n",
    "                    all_p = [num,k,d,g]\n",
    "                    # print(all_m)\n",
    "                    write_csv_result(path_a,path_p,all_m,all_p)              \n",
    "                    if(rmse < best_result):\n",
    "                        joblib.dump(filename=model_path,value=model,compress=True)\n",
    "                        with open(path_b,\"w\",encoding=\"utf-8\",newline=\"\")as f:\n",
    "                            f = csv.writer(f)\n",
    "                            f.writerow([num,mse,rmse,mae,r2,mad,mape,r2_adjusted])\n",
    "                            f.writerow([num,mse1,rmse1,mae1,r21,mad1,mape1,r2_adjusted1])\n",
    "                            f.writerow([num,mse2,rmse2,mae2,r22,mad2,mape2,r2_adjusted2])\n",
    "                            f.writerow([num,mse3,rmse3,mae3,r23,mad3,mape3,r2_adjusted3])\n",
    "                        best_result = rmse\n",
    "                        print(\"current best result, mse:{},mae:{},rmse:{},mad:{},r2:{},mape:{},r2 adjusted:{}\".format(mse,mad,rmse,mad,r2,mape,r2_adjusted))\n",
    "                    print(\"end....\",num)\n",
    "                    num = num+1\n",
    "                    print(\"--------------------------------\")\n",
    "\n",
    "\n",
    "name='Migration'\n",
    "Svr(x_train,x_test,y_train,y_test,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
