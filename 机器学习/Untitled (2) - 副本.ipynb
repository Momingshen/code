{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:33:29.705528Z",
     "start_time": "2020-12-23T14:33:29.673613Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install keras==2.2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import keras \n",
    "# from keras_preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:41:29.176816Z",
     "start_time": "2020-12-23T14:41:29.158864Z"
    }
   },
   "outputs": [],
   "source": [
    "def readTrain():\n",
    "    train = pd.read_csv(\"./SPY.csv\")\n",
    "    return train\n",
    "\n",
    "def augFeatures(train):\n",
    "    train[\"Date\"]=train.index\n",
    "    train[\"Date\"] = pd.to_datetime(train[\"Date\"])\n",
    "    train[\"year\"] = train[\"Date\"].dt.year\n",
    "    train[\"month\"] = train[\"Date\"].dt.month\n",
    "    train[\"date\"] = train[\"Date\"].dt.day\n",
    "    train[\"day\"] = train[\"Date\"].dt.dayofweek\n",
    "    return train\n",
    "\n",
    "def normalize(train):\n",
    "    train = train.drop([\"Date\"], axis=1)\n",
    "    train_norm = train.apply(lambda x: (x - np.mean(x)) / (np.std(x)))\n",
    "    p=pd.DataFrame([train.mean(),train.std()])\n",
    "    print(p)\n",
    "    return train_norm,p\n",
    "\n",
    "def normalize1(train):\n",
    "    train = train.drop([\"Date\"], axis=1)\n",
    "    train_norm = train.apply(lambda x: np.arctan(x)*2/np.pi)\n",
    "    return train_norm\n",
    "\n",
    "def buildTrain(train, pastDay=30, futureDay=5):\n",
    "    X_train, Y_train = [], []\n",
    "    for i in range(train.shape[0]-futureDay-pastDay):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "        Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"Adj Close\"]))\n",
    "    return np.array(X_train), np.array(Y_train)\n",
    "\n",
    "def shuffle(X,Y):\n",
    "    np.random.seed(10)\n",
    "    randomList = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return X[randomList], Y[randomList]\n",
    "\n",
    "def splitData(X,Y,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "def buildManyToOneModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(8, input_length=shape[1], input_dim=shape[2]))\n",
    "    # output shape: (1, 1)\n",
    "    model.add(Dense(8))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def splitData1(X,rate):\n",
    "    x_train = X[:int(X.shape[0]*rate)].drop('close',axis=1)\n",
    "    y_train = X[:int(X.shape[0]*rate)]['close']\n",
    "    x_val = X[int(X.shape[0]*rate):int(X.shape[0]*(rate+(1-rate)/2))].drop('close',axis=1)\n",
    "    y_val = X[int(X.shape[0]*rate):int(X.shape[0]*(rate+(1-rate)/2))]['close']\n",
    "    x_test = X[int(X.shape[0]*(rate+(1-rate)/2)):].drop('close',axis=1)\n",
    "    y_test = X[int(X.shape[0]*(rate+(1-rate)/2)):]['close']\n",
    "    return x_train, y_train, x_val, y_val,x_test ,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:52:17.505371Z",
     "start_time": "2020-12-23T14:52:06.618493Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install numpy==1.19.3 -i  http://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com \n",
    "# !pip install akshare -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com  --upgrade\n",
    "import akshare as ak\n",
    "code=\"sh600519\"\n",
    "df = ak.stock_zh_index_daily_tx(symbol=code)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:33:32.036292Z",
     "start_time": "2020-12-23T14:33:32.010365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         open       close        high         low        amount         year  \\\n",
      "0  261.100805  261.572454  264.678426  258.103375  28278.221014  2010.898136   \n",
      "1  379.117117  379.831571  383.816459  375.270613  24180.430128     5.587685   \n",
      "\n",
      "      month       date       day  \n",
      "0  6.716515  16.184439  2.004985  \n",
      "1  3.430117   8.581157  1.408753  \n"
     ]
    }
   ],
   "source": [
    "train = df\n",
    "train_Aug = augFeatures(train)\n",
    "train_norm,p = normalize(train_Aug)\n",
    "# change the last day and next day\n",
    "# train_norm = train_Aug.drop([\"Date\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:33:41.431189Z",
     "start_time": "2020-12-23T14:33:41.428167Z"
    }
   },
   "outputs": [],
   "source": [
    "train_norm['close']=train_norm['close'].shift(-7)\n",
    "train_norm=train_norm[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:33:41.964766Z",
     "start_time": "2020-12-23T14:33:41.955758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4607, 9)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:39:07.922716Z",
     "start_time": "2020-12-23T14:39:07.667391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 553\n",
      "Trainable params: 553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#切分数据集\n",
    "x_train, y_train, x_val, y_val,x_test ,y_test=splitData1(train_norm,0.8)\n",
    "#转换成数组形式\n",
    "x_train, y_train, x_val, y_val,x_test ,y_test=np.array(x_train),np.array(y_train),np.array(x_val),np.array(y_val),np.array(x_test),np.array(y_test)\n",
    "#增加一个维度\n",
    "x_train, y_train, x_val, y_val,x_test ,y_test=x_train.reshape(x_train.shape[0],1,x_train.shape[1]),y_train.reshape(y_train.shape[0],1),x_val.reshape(x_val.shape[0],1,x_val.shape[1]),y_val.reshape(y_val.shape[0],1),x_test.reshape(x_test.shape[0],1,x_test.shape[1]),y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "# X_train, Y_train = buildTrain(train_norm, 30, 1)\n",
    "# X_train, Y_train = shuffle(X_train, Y_train)\n",
    "# # because no return sequence, Y_train and Y_val shape must be 2 dimension\n",
    "# X_train, Y_train, X_val, Y_val = splitData(X_train, Y_train, 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:46:15.530749Z",
     "start_time": "2020-12-23T14:46:00.026223Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 625\n",
      "Trainable params: 625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 0.1151 - val_loss: 0.6958\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0324 - val_loss: 0.7215\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0151 - val_loss: 0.7365\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0096 - val_loss: 0.7176\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0072 - val_loss: 0.6830\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0060 - val_loss: 0.6447\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.6054\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 0.5717\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.5401\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.5097\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.4790\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.4540\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0029 - val_loss: 0.4293\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.4065\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.3863\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.3700\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.3548\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0017 - val_loss: 0.3438\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0015 - val_loss: 0.3333\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0014 - val_loss: 0.3268\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0012 - val_loss: 0.3218\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0011 - val_loss: 0.3183\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0010 - val_loss: 0.3168\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 9.0774e-04 - val_loss: 0.3166\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 8.3060e-04 - val_loss: 0.3162\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 7.6219e-04 - val_loss: 0.3172\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 7.0611e-04 - val_loss: 0.3188\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.5972e-04 - val_loss: 0.3211\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 6.1748e-04 - val_loss: 0.3228\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.8615e-04 - val_loss: 0.3260\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.5677e-04 - val_loss: 0.3272\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.3238e-04 - val_loss: 0.3300\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 5.1196e-04 - val_loss: 0.3301\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.9422e-04 - val_loss: 0.3321\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.8107e-04 - val_loss: 0.3327\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.6981e-04 - val_loss: 0.3344\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.5675e-04 - val_loss: 0.3350\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.4758e-04 - val_loss: 0.3342\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.4113e-04 - val_loss: 0.3345\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.3381e-04 - val_loss: 0.3348\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.2683e-04 - val_loss: 0.3334\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.1976e-04 - val_loss: 0.3334\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.1179e-04 - val_loss: 0.3324\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 4.1007e-04 - val_loss: 0.3314\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 4.0783e-04 - val_loss: 0.3306\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9873e-04 - val_loss: 0.3295\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.9408e-04 - val_loss: 0.3272\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.8844e-04 - val_loss: 0.3255\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.8530e-04 - val_loss: 0.3249\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.8381e-04 - val_loss: 0.3230\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7773e-04 - val_loss: 0.3220\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.7353e-04 - val_loss: 0.3208\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 1s 21ms/step - loss: 3.7213e-04 - val_loss: 0.3189\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6999e-04 - val_loss: 0.3165\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6669e-04 - val_loss: 0.3170\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6368e-04 - val_loss: 0.3142\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.6049e-04 - val_loss: 0.3140\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.5834e-04 - val_loss: 0.3112\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.5409e-04 - val_loss: 0.3079\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.5091e-04 - val_loss: 0.3066\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.4935e-04 - val_loss: 0.3049\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.4997e-04 - val_loss: 0.3042\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.4747e-04 - val_loss: 0.3027\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.4440e-04 - val_loss: 0.3002\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.4486e-04 - val_loss: 0.2979\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3935e-04 - val_loss: 0.2972\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3763e-04 - val_loss: 0.2946\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3562e-04 - val_loss: 0.2943\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3261e-04 - val_loss: 0.2910\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.3043e-04 - val_loss: 0.2889\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2940e-04 - val_loss: 0.2878\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2831e-04 - val_loss: 0.2852\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2632e-04 - val_loss: 0.2842\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2661e-04 - val_loss: 0.2825\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2486e-04 - val_loss: 0.2801\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2647e-04 - val_loss: 0.2802\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.2155e-04 - val_loss: 0.2762\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1955e-04 - val_loss: 0.2752\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1792e-04 - val_loss: 0.2739\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1873e-04 - val_loss: 0.2707\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1756e-04 - val_loss: 0.2702\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1335e-04 - val_loss: 0.2686\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1088e-04 - val_loss: 0.2662\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1270e-04 - val_loss: 0.2647\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1220e-04 - val_loss: 0.2623\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1416e-04 - val_loss: 0.2612\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.1011e-04 - val_loss: 0.2597\n",
      "Epoch 88/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0904e-04 - val_loss: 0.2573\n",
      "Epoch 89/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0741e-04 - val_loss: 0.2565\n",
      "Epoch 90/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0531e-04 - val_loss: 0.2544\n",
      "Epoch 91/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0536e-04 - val_loss: 0.2540\n",
      "Epoch 92/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0543e-04 - val_loss: 0.2511\n",
      "Epoch 93/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0451e-04 - val_loss: 0.2512\n",
      "Epoch 94/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0233e-04 - val_loss: 0.2486\n",
      "Epoch 95/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0414e-04 - val_loss: 0.2464\n",
      "Epoch 96/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9903e-04 - val_loss: 0.2438\n",
      "Epoch 97/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0005e-04 - val_loss: 0.2436\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0028e-04 - val_loss: 0.2439\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 3.0088e-04 - val_loss: 0.2420\n",
      "Epoch 100/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9755e-04 - val_loss: 0.2386\n",
      "Epoch 101/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9703e-04 - val_loss: 0.2380\n",
      "Epoch 102/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9830e-04 - val_loss: 0.2363\n",
      "Epoch 103/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9714e-04 - val_loss: 0.2342\n",
      "Epoch 104/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9682e-04 - val_loss: 0.2338\n",
      "Epoch 105/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9513e-04 - val_loss: 0.2323\n",
      "Epoch 106/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9455e-04 - val_loss: 0.2307\n",
      "Epoch 107/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9258e-04 - val_loss: 0.2296\n",
      "Epoch 108/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9154e-04 - val_loss: 0.2276\n",
      "Epoch 109/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8927e-04 - val_loss: 0.2266\n",
      "Epoch 110/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9254e-04 - val_loss: 0.2269\n",
      "Epoch 111/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9155e-04 - val_loss: 0.2215\n",
      "Epoch 112/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9377e-04 - val_loss: 0.2218\n",
      "Epoch 113/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9168e-04 - val_loss: 0.2221\n",
      "Epoch 114/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9065e-04 - val_loss: 0.2206\n",
      "Epoch 115/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8904e-04 - val_loss: 0.2182\n",
      "Epoch 116/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8890e-04 - val_loss: 0.2176\n",
      "Epoch 117/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8975e-04 - val_loss: 0.2168\n",
      "Epoch 118/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8777e-04 - val_loss: 0.2152\n",
      "Epoch 119/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8689e-04 - val_loss: 0.2139\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9000e-04 - val_loss: 0.2135\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8728e-04 - val_loss: 0.2130\n",
      "Epoch 122/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.9260e-04 - val_loss: 0.2109\n",
      "Epoch 123/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8911e-04 - val_loss: 0.2105\n",
      "Epoch 124/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8618e-04 - val_loss: 0.2100\n",
      "Epoch 125/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8807e-04 - val_loss: 0.2084\n",
      "Epoch 126/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8516e-04 - val_loss: 0.2081\n",
      "Epoch 127/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8502e-04 - val_loss: 0.2063\n",
      "Epoch 128/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8493e-04 - val_loss: 0.2036\n",
      "Epoch 129/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8427e-04 - val_loss: 0.2048\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8304e-04 - val_loss: 0.2018\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8492e-04 - val_loss: 0.2013\n",
      "Epoch 132/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8375e-04 - val_loss: 0.2020\n",
      "Epoch 133/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8325e-04 - val_loss: 0.2006\n",
      "Epoch 134/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8183e-04 - val_loss: 0.2012\n",
      "Epoch 135/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8390e-04 - val_loss: 0.1996\n",
      "Epoch 136/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8046e-04 - val_loss: 0.2002\n",
      "Epoch 137/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8184e-04 - val_loss: 0.1991\n",
      "Epoch 138/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8025e-04 - val_loss: 0.1979\n",
      "Epoch 139/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8290e-04 - val_loss: 0.1961\n",
      "Epoch 140/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8260e-04 - val_loss: 0.1960\n",
      "Epoch 141/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8521e-04 - val_loss: 0.1950\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8004e-04 - val_loss: 0.1952\n",
      "Epoch 143/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7865e-04 - val_loss: 0.1939\n",
      "Epoch 144/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8343e-04 - val_loss: 0.1938\n",
      "Epoch 145/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7797e-04 - val_loss: 0.1934\n",
      "Epoch 146/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7925e-04 - val_loss: 0.1950\n",
      "Epoch 147/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 3.6030e-0 - 0s 2ms/step - loss: 2.7907e-04 - val_loss: 0.1934\n",
      "Epoch 148/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8012e-04 - val_loss: 0.1917\n",
      "Epoch 149/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7724e-04 - val_loss: 0.1933\n",
      "Epoch 150/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7944e-04 - val_loss: 0.1921\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7793e-04 - val_loss: 0.1878\n",
      "Epoch 152/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.8046e-04 - val_loss: 0.1891\n",
      "Epoch 153/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7473e-04 - val_loss: 0.1906\n",
      "Epoch 154/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7419e-04 - val_loss: 0.1867\n",
      "Epoch 155/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7431e-04 - val_loss: 0.1897\n",
      "Epoch 156/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7408e-04 - val_loss: 0.1880\n",
      "Epoch 157/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7482e-04 - val_loss: 0.1888\n",
      "Epoch 158/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7548e-04 - val_loss: 0.1870\n",
      "Epoch 159/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7624e-04 - val_loss: 0.1880\n",
      "Epoch 160/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7362e-04 - val_loss: 0.1862\n",
      "Epoch 161/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7577e-04 - val_loss: 0.1851\n",
      "Epoch 162/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7298e-04 - val_loss: 0.1845\n",
      "Epoch 163/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7383e-04 - val_loss: 0.1853\n",
      "Epoch 164/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7432e-04 - val_loss: 0.1837\n",
      "Epoch 165/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7545e-04 - val_loss: 0.1846\n",
      "Epoch 166/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7246e-04 - val_loss: 0.1850\n",
      "Epoch 167/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7416e-04 - val_loss: 0.1840\n",
      "Epoch 168/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7479e-04 - val_loss: 0.1839\n",
      "Epoch 169/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7743e-04 - val_loss: 0.1835\n",
      "Epoch 170/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7918e-04 - val_loss: 0.1826\n",
      "Epoch 171/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7074e-04 - val_loss: 0.1830\n",
      "Epoch 172/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7513e-04 - val_loss: 0.1812\n",
      "Epoch 173/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7282e-04 - val_loss: 0.1829\n",
      "Epoch 174/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7193e-04 - val_loss: 0.1820\n",
      "Epoch 175/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7376e-04 - val_loss: 0.1815\n",
      "Epoch 176/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7553e-04 - val_loss: 0.1823\n",
      "Epoch 177/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7551e-04 - val_loss: 0.1804\n",
      "Epoch 178/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7407e-04 - val_loss: 0.1779\n",
      "Epoch 179/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7318e-04 - val_loss: 0.1812\n",
      "Epoch 180/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7367e-04 - val_loss: 0.1798\n",
      "Epoch 181/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6947e-04 - val_loss: 0.1803\n",
      "Epoch 182/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7346e-04 - val_loss: 0.1782\n",
      "Epoch 183/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7231e-04 - val_loss: 0.1796\n",
      "Epoch 184/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7400e-04 - val_loss: 0.1793\n",
      "Epoch 185/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.6973e-04 - val_loss: 0.1777\n",
      "Epoch 186/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7082e-04 - val_loss: 0.1798\n",
      "Epoch 187/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7174e-04 - val_loss: 0.1769\n",
      "Epoch 188/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7195e-04 - val_loss: 0.1782\n",
      "Epoch 189/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7233e-04 - val_loss: 0.1800\n",
      "Epoch 190/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7425e-04 - val_loss: 0.1776\n",
      "Epoch 191/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7709e-04 - val_loss: 0.1780\n",
      "Epoch 192/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7320e-04 - val_loss: 0.1785\n",
      "Epoch 193/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7845e-04 - val_loss: 0.1761\n",
      "Epoch 194/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7164e-04 - val_loss: 0.1768\n",
      "Epoch 195/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7493e-04 - val_loss: 0.1771\n",
      "Epoch 196/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7226e-04 - val_loss: 0.1777\n",
      "Epoch 197/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7247e-04 - val_loss: 0.1755\n",
      "Epoch 198/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7376e-04 - val_loss: 0.1770\n",
      "Epoch 199/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7876e-04 - val_loss: 0.1790\n",
      "Epoch 200/200\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 2.7168e-04 - val_loss: 0.1752\n"
     ]
    }
   ],
   "source": [
    "model = buildManyToOneModel(x_train.shape)\n",
    "# callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "# history=model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_val, y_val), callbacks=[callback])\n",
    "history=model.fit(x_train, y_train, epochs=200, batch_size=128, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:46:15.831967Z",
     "start_time": "2020-12-23T14:46:15.705277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b157a008b0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs=range(len(history.history['loss']))\n",
    "plt.figure()\n",
    "plt.plot(epochs,history.history['loss'],'b',label='Training loss')\n",
    "plt.plot(epochs,history.history['val_loss'],'r',label='Validation val_loss')\n",
    "plt.legend()\n",
    "# plt.savefig('/root/notebook/help/figure/model_V3.1_loss.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:46:29.619092Z",
     "start_time": "2020-12-23T14:46:29.297914Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict=model.predict(x_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# mean_squared_error(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:46:30.363064Z",
     "start_time": "2020-12-23T14:46:30.358078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.287453139166945"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:49:29.462038Z",
     "start_time": "2020-12-23T14:49:29.430014Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize2(df):\n",
    "#     df=df.drop('Date',axis=1)\n",
    "    for i in df.columns:\n",
    "        df[i]=df[i].apply(lambda x:(x-p[i][0])/(p[i][1]-p[i][2]))\n",
    "    return df\n",
    "def notnormalize2(y_predict1):\n",
    "    y_predict2=[]\n",
    "    for i in y_predict1:\n",
    "        y_predict2.append(p['close'][0]+(i*p['close'][1]))\n",
    "    return y_predict2\n",
    "pred_test=notnormalize2(y_predict)\n",
    "y_test=notnormalize2(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:02:47.978629Z",
     "start_time": "2020-12-23T14:02:47.975637Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.plot(np.arange(1,len(y_test)+1),y_test, 'r-',label='Test')\n",
    "# plt.plot(np.arange(1,len(pred_test)+1),pred_test, 'g-',label='pred_test')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()\n",
    "\n",
    "# plt.xlabel('pred_test')\n",
    "# plt.ylabel('y_test')\n",
    "# plt.scatter(pred_test,y_test,marker='.')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:50:11.959355Z",
     "start_time": "2020-12-23T14:50:07.348572Z"
    }
   },
   "outputs": [],
   "source": [
    "df = ak.stock_zh_index_daily_tx(symbol=\"sh000919\")\n",
    "d=df[-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:50:12.189620Z",
     "start_time": "2020-12-23T14:50:12.178649Z"
    }
   },
   "outputs": [],
   "source": [
    "d1=augFeatures(d)\n",
    "date=d1['Date'][-1]\n",
    "# d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:50:55.086894Z",
     "start_time": "2020-12-23T14:50:55.074891Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize2(df):\n",
    "    df=df.drop('Date',axis=1)\n",
    "    for i in df.columns:\n",
    "        df[i]=df[i].apply(lambda x:(x-p[i][0])/(p[i][1]))\n",
    "    return df\n",
    "d1 = normalize2(d1)\n",
    "d2=d1.drop('close',axis=1)\n",
    "# d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:50:56.902028Z",
     "start_time": "2020-12-23T14:50:56.899011Z"
    }
   },
   "outputs": [],
   "source": [
    "d2=np.array(d2).reshape(d2.shape[0],1,d2.shape[1])\n",
    "# d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:50:57.780657Z",
     "start_time": "2020-12-23T14:50:57.750733Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predict1=model.predict(d2)\n",
    "# y_predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:51:11.507929Z",
     "start_time": "2020-12-23T14:51:11.503939Z"
    }
   },
   "outputs": [],
   "source": [
    "def notnormalize2(y_predict1):\n",
    "    y_predict2=[]\n",
    "    for i in y_predict1:\n",
    "        y_predict2.append(p['close'][0]+i*(p['close'][1]))\n",
    "    return y_predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:51:17.460038Z",
     "start_time": "2020-12-23T14:51:17.456016Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_test=notnormalize2(y_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:51:19.560416Z",
     "start_time": "2020-12-23T14:51:19.558395Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:54:45.061645Z",
     "start_time": "2020-12-23T14:54:45.057627Z"
    }
   },
   "outputs": [],
   "source": [
    "d3=pd.DataFrame(y_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:54:45.641097Z",
     "start_time": "2020-12-23T14:54:45.637077Z"
    }
   },
   "outputs": [],
   "source": [
    "msg=str(date).split(' ')[0]+'之后7天的预测值'+str(d3[0].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T14:54:46.169679Z",
     "start_time": "2020-12-23T14:54:45.924308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.get('https://sc.ftqq.com/SCU128831T37074ab313300c27cb0187ed02ae06215fba1a3315473.send?text=' +code+ '&desp=预测情况：' + msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T08:34:15.285637Z",
     "start_time": "2021-01-12T08:31:40.080884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pyspark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
      "    pyspark from https://pypi.tuna.tsinghua.edu.cn/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz#sha256=38b485d3634a86c9a2923c39c8f08f003fdd0e0a3d7f07114b2fb4392ce60479:\n",
      "        Expected sha256 38b485d3634a86c9a2923c39c8f08f003fdd0e0a3d7f07114b2fb4392ce60479\n",
      "             Got        dffdf74d792c037196c5d956ecda48ab0e8cf4c7a3f1cbe193bc1e8bca1b2c74\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2 MB)\n"
     ]
    }
   ],
   "source": [
    "!pip --default-timeout=6666 install pyspark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
