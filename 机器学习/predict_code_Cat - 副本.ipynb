{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################start##############################\n",
    "import pandas as pd\n",
    "df=pd.read_csv('./datas/Data_MergeNew.csv',index_col=0)\n",
    "df.index=pd.to_datetime(df.date,format='%Y-%m-%d') \n",
    "df.drop('date',axis=1,inplace=True)\n",
    "df_train=df.loc['2020-01-07':'2021-04-02'] \n",
    "df_test=df.loc['2021-04-02':'2021-04-23']\n",
    "\n",
    "name=['cityin','cityto','incity','city']\n",
    "name1=['cityin','cityto','incity']\n",
    "x_train=df_train.drop(name,axis=1).values  \n",
    "y_train=df_train[name1].values\n",
    "x_test=df_test.drop(name,axis=1).values  \n",
    "y_test=df_test[name1].values\n",
    "print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "#####################标准化##############################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss.fit(x_train)\n",
    "x_train = ss.transform(x_train) \n",
    "x_test = ss.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 中文字体设置-黑体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决保存图像是负号'-'显示为方块的问题\n",
    "sns.set(font='SimHei',font_scale=1.5)  # 解决Seaborn中文显示问题并调整字体大小\n",
    "sns.set_style(\"white\")\n",
    "def mkdir(path):\n",
    "    folder = os.path.exists(path)\n",
    "    if not folder:                   \n",
    "        os.makedirs(path)            \n",
    "        print(\"---  new folder...  ---\")\n",
    "        print(\"---  OK  ---\")\n",
    "    else:\n",
    "        print(\"---  There is this folder!  ---\")\n",
    "mkdir(\"./results_merge/\")        \n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,median_absolute_error,r2_score,mean_squared_log_error\n",
    "\n",
    "def calculate(y_true, y_predict, n, p):\n",
    "    y_true = y_true\n",
    "    y_predict = y_predict\n",
    "    mse = mean_squared_error(y_true, y_predict)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_predict))\n",
    "    mae = mean_absolute_error(y_true, y_predict)\n",
    "    r2 = r2_score(y_true, y_predict)\n",
    "    mad = median_absolute_error(y_true, y_predict)\n",
    "    mape = np.mean(np.abs((y_true - y_predict) / y_true)) * 100\n",
    "    r2_adjusted = 1-((1-r2)*(n-1))/(n-p-1)\n",
    "    # print('MSE: ', mse)\n",
    "    # print('RMSE: ', rmse)\n",
    "    # print('MAE: ', mae)\n",
    "    # print('R2: ', r2)\n",
    "    # print('MAD:', mad)\n",
    "    # print('MAPE:', mape)\n",
    "    # print('R2_Adjusted: ',r2_adjusted)\n",
    "    return mse,rmse,mae,r2,mad,mape,r2_adjusted\n",
    "# 将参数和评估结果写入文件\n",
    "def write_csv_result(path_1,path_2,all_metrics,all_parameter):\n",
    "    with open(path_1,\"a\",encoding=\"utf-8\",newline=\"\")as f:\n",
    "        f = csv.writer(f)\n",
    "        f.writerow(all_metrics)\n",
    "    with open(path_2,\"a\",encoding=\"utf-8\",newline=\"\")as f:\n",
    "        f = csv.writer(f)\n",
    "        f.writerow(all_parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.multioutput import RegressorChain\n",
    "def Cat(train_x,test_x,train_y,test_y,name):\n",
    "    path_a = \"./results_merge/\" + \"Cat_\" + name + \"_\" + \"assess.csv\"\n",
    "    path_p = \"./results_merge/\" + \"Cat_\" + name + \"_\" + \"parameter.csv\"\n",
    "    path_b = \"./results_merge/\" + \"Cat_\" + name + \"_\" + \"best.csv\"\n",
    "    model_path = \"./results_merge/\" + \"Cat_\" + name + \"_\" + \"best.m\"\n",
    "    all_assessed_values = []\n",
    "    all_parameter = []\n",
    "    depth=[5,6,7,8,9,10]\n",
    "    learning_rate=[0.001,0.01,0.03,0.05,0.07,0.09,0.1,0.2,0.3]\n",
    "    iterations = [1500,1400,1300,1200,1100,1000,900,800]\n",
    "    l2_leaf_reg = [0,1,2,3,4,5]\n",
    "    all_nb = len(depth)*len(learning_rate)*len(iterations)*len(l2_leaf_reg)\n",
    "    num=1\n",
    "    # 用于重启训练模型，提高效率，不重复跑相同的实验\n",
    "    if(os.path.exists(path_a)):\n",
    "        data = pd.read_csv(path_a)\n",
    "        if(data.shape[0]>1):\n",
    "            nums = int(data.values[-1,0])\n",
    "        else:\n",
    "            nums = 0\n",
    "    else:\n",
    "        nums = 0\n",
    "        col_a = ['num','mse','rmse','mae','r2','mad','mape','r2_adjusted']\n",
    "        col_p = ['num','depth','learning_rate','iterations','l2_leaf_reg']\n",
    "        write_csv_result(path_a,path_p,col_a,col_p)\n",
    "    # 用于保存最好的模型\n",
    "    if(os.path.exists(path_b)):\n",
    "        data = pd.read_csv(path_b)\n",
    "        if(data.shape[0]>1):\n",
    "            best_result = float(data.columns[-1])\n",
    "    else:\n",
    "        with open(path_b,\"a\",encoding=\"utf-8\",newline=\"\")as f:\n",
    "            f = csv.writer(f)\n",
    "            f.writerow(['num','mse','rmse','mae','r2','mad','mape','r2_adjusted'])\n",
    "        best_result = 10*10**30\n",
    "    for d in depth:\n",
    "        for l in learning_rate:\n",
    "            for it in iterations:\n",
    "                for l2 in l2_leaf_reg:\n",
    "                    if(nums>=num):\n",
    "                        num = num+1\n",
    "                    else:\n",
    "                        print(\"train...{}/{}\".format(num,all_nb))\n",
    "                        model = cb.CatBoostRegressor(depth=d,learning_rate=l,iterations=it,l2_leaf_reg=l2,logging_level='Silent')\n",
    "                        wrapper = RegressorChain(model)\n",
    "                        wrapper.fit(train_x,train_y)\n",
    "                        pred_test = wrapper.predict(test_x)\n",
    "#     \n",
    "                        y_test=test_y       \n",
    "                        y_test1=[]\n",
    "                        for i in y_test:\n",
    "                            y_test1.append(i[0])\n",
    "                        pred_test1=[]\n",
    "                        for i in pred_test:\n",
    "                            pred_test1.append(i[0])\n",
    "                        y_test2=[]\n",
    "                        for i in y_test:\n",
    "                            y_test2.append(i[1])\n",
    "                        pred_test2=[]\n",
    "                        for i in pred_test:\n",
    "                            pred_test2.append(i[1])\n",
    "                        y_test3=[]\n",
    "                        for i in y_test:\n",
    "                            y_test3.append(i[2])\n",
    "                        pred_test3=[]\n",
    "                        for i in pred_test:\n",
    "                            pred_test3.append(i[2])\n",
    "                        pred_test1 = np.array(pred_test1).reshape(-1,1)\n",
    "                        y_test1 = np.array(y_test1).reshape(-1,1)\n",
    "                        sample_n = pred_test1.shape[0]\n",
    "                        feature_n = x_test.shape[1]\n",
    "                        mse1,rmse1,mae1,r21,mad1,mape1,r2_adjusted1 = calculate(y_test1,pred_test1,sample_n,feature_n)\n",
    "                    \n",
    "\n",
    "                        pred_test2 = np.array(pred_test2).reshape(-1,1)\n",
    "                        y_test2 = np.array(y_test2).reshape(-1,1)\n",
    "                        sample_n = pred_test2.shape[0]\n",
    "                        feature_n = x_test.shape[1]\n",
    "                        mse2,rmse2,mae2,r22,mad2,mape2,r2_adjusted2 = calculate(y_test2,pred_test2,sample_n,feature_n)\n",
    "                        \n",
    "\n",
    "                        pred_test3 = np.array(pred_test3).reshape(-1,1)\n",
    "                        y_test3 = np.array(y_test3).reshape(-1,1)\n",
    "                        sample_n = pred_test3.shape[0]\n",
    "                        feature_n = x_test.shape[1]\n",
    "                        mse3,rmse3,mae3,r23,mad3,mape3,r2_adjusted3 = calculate(y_test3,pred_test3,sample_n,feature_n)\n",
    "        \n",
    "\n",
    "                        pred_test4 = pred_test.reshape(-1,1)\n",
    "                        y_test4 = y_test.reshape(-1,1)\n",
    "                        sample_n = pred_test4.shape[0]\n",
    "                        feature_n = x_test.shape[1]\n",
    "                        mse,rmse,mae,r2,mad,mape,r2_adjusted = (mse1+mse2+mse3)/3,(rmse1+rmse2+rmse3)/3,(mae1+mae2+mae3)/3,(r21+r22+r23)/3,(mad1+mad2+mad3)/3,(mape1+mape2+mape3)/3,(r2_adjusted1+r2_adjusted2+r2_adjusted3)/3\n",
    "                        all_m = [num,mse,rmse,mae,r2,mad,mape,r2_adjusted]\n",
    "                        all_p = [num,d,l,it,l2]\n",
    "                        # print(all_m)\n",
    "                        write_csv_result(path_a,path_p,all_m,all_p)              \n",
    "                        if(rmse < best_result):\n",
    "                            joblib.dump(filename=model_path,value=model,compress=True)\n",
    "                            # joblib.dump(model,model_path)\n",
    "                            with open(path_b,\"w\",encoding=\"utf-8\",newline=\"\")as f:\n",
    "                                f = csv.writer(f)\n",
    "                                f.writerow([num,mse,rmse,mae,r2,mad,mape,r2_adjusted])\n",
    "                                f.writerow([num,mse1,rmse1,mae1,r21,mad1,mape1,r2_adjusted1])\n",
    "                                f.writerow([num,mse2,rmse2,mae2,r22,mad2,mape2,r2_adjusted2])\n",
    "                                f.writerow([num,mse3,rmse3,mae3,r23,mad3,mape3,r2_adjusted3])\n",
    "                            best_result = rmse\n",
    "                            print(\"current best result, mse:{},mae:{},rmse:{},mad:{},r2:{},mape:{},r2 adjusted:{}\".format(mse,mad,rmse,mad,r2,mape,r2_adjusted))\n",
    "                        print(\"end....\",num)\n",
    "                        num = num+1\n",
    "                        print(\"--------------------------------\")   \n",
    "\n",
    "name='Migration'\n",
    "Cat(x_train,x_test,y_train,y_test,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import catboost as cb\n",
    "# import matplotlib.pyplot as plt\n",
    "# d = 9\n",
    "# l = 0.07\n",
    "# i = 800\n",
    "# l2 = 5\n",
    "\n",
    "# cbr = cb.CatBoostRegressor(depth=d,learning_rate=l,iterations=i,l2_leaf_reg=l2,logging_level='Silent')\n",
    "# cbr.fit(x_train,y_train)\n",
    "# pred_test = cbr.predict(x_test)\n",
    "\n",
    "# pred_test = pred_test.reshape(-1,1)\n",
    "# sample_n = pred_test.shape[0]\n",
    "# feature_n = x_test.shape[1]\n",
    "# a3=calculate(y_test,pred_test,sample_n,feature_n)\n",
    "\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plt.plot(np.arange(1,len(y_test)+1),y_test, 'r-',label='Test')\n",
    "# plt.plot(np.arange(1,len(pred_test)+1),pred_test, 'g-',label='pred_test')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()\n",
    "\n",
    "# plt.xlabel('pred_test')\n",
    "# plt.ylabel('y_test')\n",
    "# plt.scatter(pred_test,y_test,marker='.')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
